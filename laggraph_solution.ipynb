{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e08ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup API Keys\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"TAVILY_API_KEY\")\n",
    "_set_env(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2dc0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the LLM Object\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad832ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#websearch tool integration\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "web_search_tool = TavilySearchResults(max_results=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474e5a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agentic RAG Tool Integration: RAG\n",
    "\n",
    " from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "\n",
    "def load_documents(folder_path: str) -> List[Document]:\n",
    "    documents = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if filename.endswith('.pdf'):\n",
    "             loader = PyPDFLoader(file_path)\n",
    "        elif filename.endswith('.docx'):\n",
    "             loader = Docx2txtLoader(file_path)\n",
    "        else:\n",
    "            print(f\"Unsupported file type: {filename}\")\n",
    "            continue\n",
    "             documents.extend(loader.load())\n",
    "    return documents\n",
    "\n",
    "folder_path = \"/content/docs\"\n",
    "documents = load_documents(folder_path)\n",
    "print(f\"Loaded {len(documents)} documents from the folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7598362f",
   "metadata": {},
   "outputs": [],
   "source": [
    " text_splitter = RecursiveCharacterTextSplitter(\n",
    "     chunk_size=1000,\n",
    "     chunk_overlap=200,\n",
    "     length_function=len\n",
    " )\n",
    "\n",
    "splits = text_splitter.split_documents(documents)\n",
    "print(f\"Split the documents into {len(splits)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6707de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3732ff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "collection_name = \"my_collection\"\n",
    "vectorstore = Chroma.from_documents(\n",
    " collection_name=collection_name,\n",
    " documents=splits,\n",
    " embedding=embedding_function,\n",
    " persist_directory=\"./chroma_db\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e197b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class RagToolSchema(BaseModel):\n",
    "     question: str\n",
    "\n",
    "@tool(args_schema=RagToolSchema)\n",
    "def retriever_tool(question):\n",
    "\"\"\"Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI\"\"\"\n",
    "print(\"INSIDE RETRIEVER NODE\")\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "retriever_result = retriever.invoke(question)\n",
    "return \"\\n\\n\".join(doc.page_content for doc in retriever_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4138e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "# pass question\n",
    "retriever_results = retriever.invoke(\"Who is the founder of Futuresmart AI?\")\n",
    "print(retriever_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70afec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NL2SQL Tool Integration\n",
    "\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///collection.db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a22c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate sql query\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_sql_query(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean SQL query by removing code block syntax, various SQL tags, backticks,\n",
    "    prefixes, and unnecessary whitespace while preserving the core SQL query.\n",
    "\n",
    "    Args:\n",
    "        text (str): Raw SQL query text that may contain code blocks, tags, and backticks\n",
    "\n",
    "    Returns:\n",
    "        str: Cleaned SQL query\n",
    "    \"\"\"\n",
    "    # Step 1: Remove code block syntax and any SQL-related tags\n",
    "    # This handles variations like ```sql, ```SQL, ```SQLQuery, etc.\n",
    "    block_pattern = r\"```(?:sql|SQL|SQLQuery|mysql|postgresql)?\\s*(.*?)\\s*```\"\n",
    "    text = re.sub(block_pattern, r\"\\1\", text, flags=re.DOTALL)\n",
    "\n",
    "    # Step 2: Handle \"SQLQuery:\" prefix and similar variations\n",
    "    # This will match patterns like \"SQLQuery:\", \"SQL Query:\", \"MySQL:\", etc.\n",
    "    prefix_pattern = r\"^(?:SQL\\s*Query|SQLQuery|MySQL|PostgreSQL|SQL)\\s*:\\s*\"\n",
    "    text = re.sub(prefix_pattern, \"\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Step 3: Extract the first SQL statement if there's random text after it\n",
    "    # Look for a complete SQL statement ending with semicolon\n",
    "    sql_statement_pattern = r\"(SELECT.*?;)\"\n",
    "    sql_match = re.search(sql_statement_pattern, text, flags=re.IGNORECASE | re.DOTALL)\n",
    "    if sql_match:\n",
    "        text = sql_match.group(1)\n",
    "\n",
    "    # Step 4: Remove backticks around identifiers\n",
    "    text = re.sub(r'`([^`]*)`', r'\\1', text)\n",
    "\n",
    "    # Step 5: Normalize whitespace\n",
    "    # Replace multiple spaces with single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Step 6: Preserve newlines for main SQL keywords to maintain readability\n",
    "    keywords = ['SELECT', 'FROM', 'WHERE', 'GROUP BY', 'HAVING', 'ORDER BY',\n",
    "               'LIMIT', 'JOIN', 'LEFT JOIN', 'RIGHT JOIN', 'INNER JOIN',\n",
    "               'OUTER JOIN', 'UNION', 'VALUES', 'INSERT', 'UPDATE', 'DELETE']\n",
    "\n",
    "    # Case-insensitive replacement for keywords\n",
    "    pattern = '|'.join(r'\\b{}\\b'.format(k) for k in keywords)\n",
    "    text = re.sub(f'({pattern})', r'\\n\\1', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Step 7: Final cleanup\n",
    "    # Remove leading/trailing whitespace and extra newlines\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n', text)\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067796f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create NL2SQL tool\n",
    "\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from operator import itemgetter\n",
    "import re\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "class SQLToolSchema(BaseModel):\n",
    "     question: str\n",
    "\n",
    "@tool(args_schema=SQLToolSchema)\n",
    "def nl2sql_tool(question):\n",
    "\"\"\"Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB\"\"\"\n",
    "print(\"INSIDE NL2SQL TOOL\")\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "write_query = create_sql_query_chain(llm, db)\n",
    "\n",
    "chain = (\n",
    "   RunnablePassthrough.assign(query=write_query | RunnableLambda(clean_sql_query)).assign(\n",
    "       result=itemgetter(\"query\") | execute_query\n",
    "   )\n",
    ")\n",
    "\n",
    "response = chain.invoke({\"question\": question})\n",
    "return response['result']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3d2032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test NL2SQL tool\n",
    "\n",
    "question = \"How many employees are there?\"\n",
    "result = nl2sql_tool.invoke({\"question\": question})\n",
    "print(f\"Answer: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92bd397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining the tools\n",
    "\n",
    "tools = [web_search_tool, retriever_tool, nl2sql_tool]\n",
    "llm_with_tools = llm.bind_tools(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e1e9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps to build lanngraph\n",
    "#1. setup state\n",
    "from typing import Annotated\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3d7173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Add nodes\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[web_search_tool, retriever_tool, nl2sql_tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d1e1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Define edges\n",
    "\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bf1b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Compile graph\n",
    "\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fc2b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Interactive Testing\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}, config):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
